{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e6c74d-f0e7-4639-8b5c-c44ea39cdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e041b9-6744-4685-91a1-0df366113aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f59bde-6294-4316-9c81-00ae0dd3deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_website_content(url):\n",
    "    \"\"\"\n",
    "    Fetch the textual content of a website, ignoring irrelevant elements.\n",
    "    :param url: The URL of the website to summarize.\n",
    "    :return: Cleaned and relevant text content of the website.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Ensure request was successful\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Remove irrelevant elements like <script>, <style>, etc.\n",
    "        for element in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\", \"aside\"]):\n",
    "            element.decompose()\n",
    "\n",
    "        # Extract relevant text from <p>, <h1>, <h2>, <h3>, <li>, etc.\n",
    "        text_elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li'])\n",
    "        text = ' '.join([elem.get_text(strip=True) for elem in text_elements])\n",
    "\n",
    "        # Optional: Remove excessive whitespace\n",
    "        cleaned_text = ' '.join(text.split())\n",
    "        return cleaned_text\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the website content: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b4a8ba-c3d8-4161-a4f0-053d80f024c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, max_length=2000):\n",
    "    \"\"\"\n",
    "    Splits the text into smaller chunks, ensuring each chunk is within the maximum length.\n",
    "    :param text: The input text to split.\n",
    "    :param max_length: The maximum length of each chunk.\n",
    "    :return: A list of text chunks.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        if len(\" \".join(current_chunk + [word])) <= max_length:\n",
    "            current_chunk.append(word)\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "\n",
    "    # Add the last chunk if it exists\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a233f1f4-8f1e-4591-b857-5a93c2758692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    \"\"\"\n",
    "    Send text to the Ollama API to summarize, handling streaming responses.\n",
    "    :param text: The text to summarize.\n",
    "    :return: The summary returned by the Ollama API.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Summarize the following text.\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    }\n",
    "    try:\n",
    "        # Enable streaming by setting stream=True\n",
    "        response = requests.post(OLLAMA_API, headers=HEADERS, json=payload, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Combine the streamed chunks into a single message\n",
    "        full_message = \"\"\n",
    "        for line in response.iter_lines(decode_unicode=True):\n",
    "            if line:  # Process only non-empty lines\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    message_content = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "                    full_message += message_content\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Invalid JSON in response line:\", line)\n",
    "\n",
    "        return full_message.strip() if full_message else \"No summary returned.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error communicating with the Ollama API: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f68c75-e73c-4670-aba6-170747f2b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_large_text(text, max_length=2000):\n",
    "    \"\"\"\n",
    "    Splits large text into smaller chunks and summarizes each chunk separately.\n",
    "    :param text: The large text to summarize.\n",
    "    :param max_length: The maximum length of each chunk.\n",
    "    :return: A combined summary of the entire text.\n",
    "    \"\"\"\n",
    "    chunks = split_text_into_chunks(text, max_length)\n",
    "    summaries = []\n",
    "\n",
    "    print(f\"Text split into {len(chunks)} chunks for summarization.\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Summarizing chunk {i+1} of {len(chunks)}...\")\n",
    "        summary = summarize_text(chunk)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    # Combine all summaries into a final summary\n",
    "    final_summary = \" \".join(summaries)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ead8eb6-3ed6-4fb3-a25a-65944d13bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def website_summarizer(url):\n",
    "    \"\"\"\n",
    "    Fetches content from a website and summarizes it.\n",
    "    :param url: The URL of the website to summarize.\n",
    "    :return: The summarized text.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching content from: {url}\")\n",
    "    website_content = fetch_website_content(url)\n",
    "    if not website_content:\n",
    "        return \"Failed to fetch website content.\"\n",
    "    \n",
    "    print(\"Summarizing the content...\")\n",
    "    summary = summarize_large_text(website_content)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26f11acd-e9f6-44b2-abc2-f2d0814b9776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a website URL to summarize:  https://en.wikipedia.org/wiki/Article_(grammar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching content from: https://en.wikipedia.org/wiki/Article_(grammar)\n",
      "Summarizing the content...\n",
      "Text split into 12 chunks for summarization.\n",
      "Summarizing chunk 1 of 12...\n",
      "Summarizing chunk 2 of 12...\n",
      "Summarizing chunk 3 of 12...\n",
      "Summarizing chunk 4 of 12...\n",
      "Summarizing chunk 5 of 12...\n",
      "Summarizing chunk 6 of 12...\n",
      "Summarizing chunk 7 of 12...\n",
      "Summarizing chunk 8 of 12...\n",
      "Summarizing chunk 9 of 12...\n",
      "Summarizing chunk 10 of 12...\n",
      "Summarizing chunk 11 of 12...\n",
      "Summarizing chunk 12 of 12...\n",
      "\n",
      "Summary:\n",
      "\n",
      "The text explains the concept of articles in grammar, specifically their role in forming noun phrases and indicating the identifiability of nouns. Articles are a part of speech that provide grammatical information such as definiteness, gender, number, and case. There are two main types of articles: definite and indefinite.\n",
      "\n",
      "Definite articles (e.g. \"the\") refer to a specific member of a group, something previously mentioned or uniquely specified. Indefinite articles (e.g. \"a\" or \"an\") do not refer to a specific entity, but rather indicate that the noun phrase is non-specific or could be any one.\n",
      "\n",
      "Additionally, the text mentions that some languages have definite articles as suffixes, and recent research suggests that definiteness may not play a significant role in the selection of definite articles. The text explains different uses and examples of indefinite and proper articles in language:\n",
      "\n",
      "* Indefinite articles (a/an) are used to introduce new discourse referents, generalize over entities with common properties, or refer to specific entities whose identity is unknown.\n",
      "* Proper articles (the) indicate that the noun refers to a unique entity, such as a person's name, place, planet, etc. They can be used with both personal nouns and proper names already specified by definition.\n",
      "\n",
      "Examples of using indefinite articles include:\n",
      "- A monster ate a cookie, His name is Cookie Monster.\n",
      "- A friend of mine told me that happens frequently...\n",
      "\n",
      "Examples of using proper articles include:\n",
      "- Proper article usage in Māori language (a Pita means \"Peter\")\n",
      "- Examples like the Amazon and the Hebrides, where the definite article may be considered superfluous. The text discusses how languages use articles with names, including countries and personal names. It mentions that some languages, such as French and Italian, always use definite or partitive articles with country names, while others do not (e.g., the US uses American English nicknames without articles). The use of articles can vary depending on language, culture, and context. Additionally, the text highlights the concept of partitive articles, which indicate a non-specific quantity of an object in languages like French and Italian, but is less common in English. The text discusses articles in linguistics. Key points include:\n",
      "\n",
      "* Negative articles specify none of their noun and can be considered neither definite nor indefinite.\n",
      "* The zero article is the absence of an article and is used with plurals and mass nouns.\n",
      "* Articles are found in many languages, but not in others like Chinese, Japanese, Korean, and Mongolian.\n",
      "* In some languages, like English and German, articles are mandatory, while in others like Basque, they are optional or absent altogether.\n",
      "* The common ancestor of the Indo-European language family did not have articles, and most languages in this family do not use them. The text discusses the use of definite and indefinite articles in various languages, including Slavic, Baltic, Indo-Aryan, Greek, and others. It highlights that:\n",
      "\n",
      "* Articles developed independently in different language families\n",
      "* Not all languages have both definite and indefinite articles\n",
      "* Some languages have distinct types of articles to convey finer shades of meaning (e.g., French and Italian have a partitive article)\n",
      "* The form of the article may vary according to noun characteristics such as gender, number, or case\n",
      "* Many languages do not use articles at all, instead using other constructions like topic-comment structures\n",
      "\n",
      "Examples are given in tables for how plural nouns are formed in different languages. The text also mentions Finnish, which does not have articles, but uses colloquial expressions similar to English \"the\" and \"an\". The text lists various languages and their corresponding definite articles used to indicate possession or specificity. The articles are often suffixed to nouns, and in some cases, prefixed. Examples include:\n",
      "\n",
      "* Albanian (e.g., zogu for \"the bird\")\n",
      "* Aramaic (written from right to left)\n",
      "* Assamese\n",
      "* Bengali (with multiple options for \"the book\")\n",
      "* Bulgarian\n",
      "* Danish\n",
      "* Icelandic\n",
      "* Macedonian\n",
      "* Persian (which uses a different form of the article with \"-e\" in some contexts)\n",
      "* Romanian (with a unique article sound and use of connection vowels)\n",
      "* Swedish and Norwegian\n",
      "\n",
      "The text also mentions prefixed definite articles, such as:\n",
      "\n",
      "* Hebrew\n",
      "* Maltese The text discusses the use of definite articles in various languages. It highlights that:\n",
      "\n",
      "* In Maltese, definite and indefinite articles are distinct (e.g., nemla for \"the ant\" and sodda for \"a bed\").\n",
      "* In Latvian and Lithuanian, the adjective is sometimes optional when using the definite article.\n",
      "* In Tokelauan, the definite article \"te\" can be used as both a definite and indefinite article, and its translation to English depends on the context.\n",
      "\n",
      "It also notes that in some languages (like Maltese), the articles are distinct, while in others (like Latvian and Lithuanian), they may not change, but the adjective may need to be defined or undefined. The text distinguishes between constructed languages like Latvian and Lithuanian, which have been intentionally created, and Tokelauan, a naturally spoken language with unique features. The text discusses the use of \"he\", \"the\", and \"te\" as indefinite and definite articles in the Tokelauan language. Key points include:\n",
      "\n",
      "* \"He\" is often used with negatives, interrogatives, and to indicate a singular noun.\n",
      "* \"Nā\" is used for plural definite nouns, but sometimes \"nā\" is not used before certain nouns (e.g. large amounts or specific classes).\n",
      "* The article \"nā\" is used in general statements about cows, while the phrase \"te ko\" is used as a preposition to indicate a class of things.\n",
      "* Articles often develop through specialization of adjectives and determiners, and can evolve from demonstratives to become generic articles and then noun markers.\n",
      "\n",
      "The text also touches on the historical development of articles in languages, including Tokelauan, which became more analytic and lost inflection over time. The text discusses the origins and meanings of definite articles in various languages. It explains that many Romance languages use Latin-derived demonstratives to form their definite articles, such as \"the\" in English, which comes from Old English's \"þe\" or \"þæt\". The text also highlights examples from other languages, including Macedonian (which uses suffixes), Colognian (prepositions with different forms for specific contexts), Basque (which distinguishes between proximal and distal articles), and Assyrian Neo-Aramaic. The text discusses the formation and use of definite and indefinite articles in various languages, including Aramaic, Indonesian, Romance languages, Persian, and English. It explains that:\n",
      "\n",
      "* In some languages, such as Aramaic, demonstratives like \"ahaandaya\" (this) and \"owa\" (that) are used to indicate the presence of a noun instead of using a definite article.\n",
      "* Indefinite articles often arise from adjectives meaning one, such as Latin's \"unus\" and English's \"an\".\n",
      "* Partitive articles derive from Vulgar Latin's \"illo\", meaning some of the, while English's indefinite article \"a\" is derived from the same root.\n",
      "* The use of definite and indefinite articles has led to changes in language usage, such as the loss of junctures like \"the\" in words like \"napron\".\n",
      "\n",
      "Overall, the text highlights the complexities of linguistic history and how different languages have developed their own systems for indicating definiteness and indefiniteness. The provided text does not appear to be a summary of an article. Instead, it seems to be a collection of citations and references from various sources, including academic articles and books. The references are related to linguistics and the study of language contact, including topics such as grammatical structures, syntax, and morphology.\n",
      "\n",
      "If you would like, I can try to summarize one of the specific articles or texts listed in the references, or provide a general overview of the topic based on the cited materials. This appears to be a list of linguistic categories, including various parts of speech and grammatical functions. The list includes terms such as Demonstrative, Disjunctive, Distributive, Interrogative, Possessive, Reciprocal, and many others, each with varying levels of specificity (e.g., strong vs. weak). It also appears to be related to language and linguistics, but does not provide any specific text or context for explanation.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example URL\n",
    "    url = input(\"Enter a website URL to summarize: \")\n",
    "    summary = website_summarizer(url)\n",
    "    print(\"\\nSummary:\\n\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33880514-3127-4640-9953-60f6ad4e3846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
